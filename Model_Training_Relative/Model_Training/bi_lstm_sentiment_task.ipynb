{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ccea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784633c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = r\"Sentiment_classification_training_dataset.xlsx\"\n",
    "df = pd.read_excel(dataset_file)\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224281a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"text\"]\n",
    "label = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保留前幾常見的詞\n",
    "max_words = 20000  \n",
    "tokenizer = Tokenizer(num_words=max_words)  \n",
    "\n",
    "# Tokenization，統計現有文字，建立 token 字典\n",
    "tokenizer.fit_on_texts(text)    \n",
    "\n",
    "# 用此 token 字典將文字轉換成編號列表 \n",
    "sequences = tokenizer.texts_to_sequences(text)\n",
    "\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93359294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最多保留 128 個詞，超出截斷，不足則以 0 補齊\n",
    "max_len = 128   \n",
    "\n",
    "# padding or truncate 都從後面做\n",
    "X_text = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "print(X_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74926479",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = to_categorical(label, num_classes=3)\n",
    "\n",
    "print(f\"{label[0]} => {y_label[0]}\")\n",
    "print(f\"{label[500]} => {y_label[500]}\")\n",
    "print(f\"{label[3400]} => {y_label[3400]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a592846",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, validation_text, train_label, validation_label = train_test_split(\n",
    "    X_text, y_label, test_size=0.25, random_state=42, stratify=label)\n",
    "\n",
    "print(train_text[0], train_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd7c9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # 要 Embedding 的詞彙表, Embedding 成多少維度 \n",
    "    Embedding(input_dim=max_words, output_dim=128),\n",
    "    Bidirectional(LSTM(128)),\n",
    "    Dropout(0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8b7055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(),                     \n",
    "    loss='categorical_crossentropy',      \n",
    "    metrics=['accuracy']                  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dfbef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_text, train_label,\n",
    "    epochs=10,          \n",
    "    batch_size=256,       \n",
    "    validation_data=(validation_text, validation_label)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Bi-LSTM_SENTIMENT_TASK.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "043d9dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_json = tokenizer.to_json()\n",
    "with open('bi_lstm_sentiment_task_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(token_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "import json\n",
    "\n",
    "# 模型下載\n",
    "model = load_model(\"Bi-LSTM_ESG_TASK.h5\")\n",
    "\n",
    "# Tokenizer 下載\n",
    "with open('bi_lstm_esg_task_tokenizer.json', 'r', encoding='utf-8') as f:\n",
    "    token_dict = json.load(f)\n",
    "    \n",
    "tokenizer = tokenizer_from_json(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理文本\n",
    "test_text = [\"This is testing text\"]\n",
    "\n",
    "seqence = tokenizer.texts_to_sequences(test_text)\n",
    "\n",
    "X_new = pad_sequences(seqence, maxlen=128, padding='post', truncating='post')\n",
    "\n",
    "# 推論\n",
    "pred = model.predict(X_new)  \n",
    "label = np.argmax(pred, axis=1)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
