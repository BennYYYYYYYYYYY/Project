{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50032ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c5f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = r\"Sentiment_classification_training_dataset.xlsx\"\n",
    "df = pd.read_excel(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_row = Dataset.from_pandas(df, split='train')\n",
    "dataset_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3de39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, ClassLabel\n",
    "\n",
    "# 為了使 label 平均分配，須將 int 轉換為 ClassLabel，使 HF 知道這四個類別對應的名稱，順序與 Label 對應\n",
    "label_feature = ClassLabel(names=[ \n",
    "    \"neutral\",  # 0\n",
    "    \"positive\", # 1\n",
    "    \"negative\"  # 2\n",
    "])\n",
    "\n",
    "# 使 label cast 成 ClassLabel，註記類別名稱\n",
    "datasets_row = dataset_row.cast_column(\n",
    "    \"label\",\n",
    "    label_feature\n",
    ")\n",
    "\n",
    "print(datasets_row.features[\"label\"], datasets_row.features[\"label\"].num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e644a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = datasets_row.train_test_split(test_size=0.20, stratify_by_column=\"label\", seed=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "def process_function(examples):\n",
    "    tokenized_examples = tokenizer(examples[\"text\"], max_length=128, truncation=True)\n",
    "    tokenized_examples[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized_examples\n",
    "\n",
    "\n",
    "tokenized_datasets = datasets.map(process_function, batched=True, remove_columns=datasets_row.column_names)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c88096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由於 FinBERT 本身是三分類的 Fine-Tuning 模型，所以需要跳過它的 classifier.weight\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\", num_labels=3, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d15ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metrics_1 = evaluate.load(\"accuracy\")\n",
    "\n",
    "metrics_2 = evaluate.combine([\n",
    "    evaluate.load(\"precision\"),          \n",
    "    evaluate.load(\"recall\"),\n",
    "    evaluate.load(\"f1\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a120c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(eval_predict):\n",
    "    preds, labels = eval_predict\n",
    "    preds = preds.argmax(axis=-1)\n",
    "\n",
    "    results = metrics_2.compute(\n",
    "        predictions=preds,\n",
    "        references=labels,\n",
    "        average=\"macro\"         \n",
    "    ) | metrics_1.compute(\n",
    "        predictions=preds,\n",
    "        references=labels\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "751420d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",      \n",
    "    per_device_train_batch_size=32,                \n",
    "    evaluation_strategy=\"epoch\",     \n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=10,           \n",
    "    save_total_limit=2,              \n",
    "    learning_rate=2e-5,              \n",
    "    weight_decay=0.01,               \n",
    "    greater_is_better=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "584ce5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  args=train_args, \n",
    "                  train_dataset=tokenized_datasets[\"train\"], \n",
    "                  eval_dataset=tokenized_datasets[\"test\"], \n",
    "                  data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "                  compute_metrics=eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f391e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"FinBERT_SENTIMENT_TASK\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
